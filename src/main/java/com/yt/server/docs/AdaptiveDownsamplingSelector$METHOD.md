# AdaptiveDownsamplingSelector 降采样方法详解

## 一、peakDetectionDownsampling (峰值检测降采样)

`com.yt.server.util.AdaptiveDownsamplingSelector#peakDetectionDownsampling` 是一个基于**特征重要性**排序的降采样算法。

它的核心思想是：**优先保留那些“弯曲程度”最大（即二阶导数绝对值最大）的点**，因为这些点通常对应着波峰、波谷或信号突变的位置，而丢弃那些在直线上或变化平缓的点。

### 核心逻辑步骤

1. **强制保留首尾**：将第一个点和最后一个点的重要性设为最大值（`Double.MAX_VALUE`），确保它们一定被选中，维持数据的时间跨度。
2. **计算重要性（曲率）**：对于中间的每一个点，计算其二阶差分（近似二阶导数）：
   > **Importance = | Next_y - 2 × Curr_y + Prev_y |**
    * 物理意义：这个值反映了当前点偏离由前后两点构成的直线的程度。如果三点共线，值为0；如果是个尖峰，值会很大。
3. **排序与筛选**：将所有点按重要性从大到小排序，选取前 `targetCount` 个最重要的点。
4. **按序重组**：将选中的点按原始索引（时间顺序）重新排序，输出结果。

### 核心原理解析：什么是二阶导数（曲率）？

简单来说，**二阶导数**描述的是**变化的快慢**，或者说**弯曲的程度**。

在数据处理中，如果说：

* **数值 ($y$)** = 汽车的位置
* **一阶导数 (斜率)** = 汽车的速度（变化的快慢）
* **二阶导数 (曲率)** = 汽车的**加速度/刹车**（速度变化的快慢）

#### 1. 公式解释

在离散的数据点中（比如 $A, B, C$ 三个连续的点），二阶导数通常通过**二阶差分**来计算：

> **二阶导数 ≈ (C - B) - (B - A) = C - 2B + A**

* $(C - B)$ 是后一段的斜率（后一个变化趋势）
* $(B - A)$ 是前一段的斜率（前一个变化趋势）
* 两者的差值，就是**趋势改变了多少**。

#### 2. 直观举例

假设我们有三个连续的时间点，看看不同的数据形态下，二阶导数（重要性）是多少：

**A. 直线行驶 (平稳/匀速) -> 二阶导数为 0**
数据：`10, 20, 30`

* **直观感受**：这是一条直线，没有弯曲。
* **一阶变化**：
    * 10变到20，涨了 10
    * 20变到30，又涨了 10
    * 速度没变。
* **二阶计算**：
  > |30 - 2 × 20 + 10| = |30 - 40 + 10| = |0|
* **结论**：**0**。这三个点在一条直线上，中间那个点 `20` 并不特殊，如果把它删了，直接连 `10` 和 `30`，形状几乎没变。所以它**不重要
  **。

**B. 缓慢加速 (平滑曲线) -> 二阶导数很小**
数据：`10, 12, 16`

* **直观感受**：开始涨得慢，后来涨得快，有一点点弯曲。
* **一阶变化**：
    * 10变到12，涨了 2
    * 12变到16，涨了 4
    * 速度变快了一点点。
* **二阶计算**：
  > |16 - 2 × 12 + 10| = |16 - 24 + 10| = |2|
* **结论**：**2**。有一点重要性，但不大。

**C. 急转弯/尖峰 (剧烈突变) -> 二阶导数极大 🔥**
数据：`10, 100, 10`

* **直观感受**：突然冲上去，又突然掉下来。这是一个尖峰（脉冲）。
* **一阶变化**：
    * 10变到100，猛涨 90 (速度极快向上)
    * 100变到10，猛跌 90 (速度极快向下)
    * 方向发生了 180度 大逆转！
* **二阶计算**：
  > |10 - 2 × 100 + 10| = |20 - 200| = |-180| => 180
* **结论**：**180**。数值非常大！中间这个 `100` 是最关键的转折点。如果把它删了，直接连两头的 `10` 和 `10`
  ，整个尖峰就消失了，数据特征就丢失了。所以它**极度重要**。

### 总结

`peakDetectionDownsampling` 算法利用这个原理：

* **数值小**（接近0）：说明是直线或平滑曲线，删了无所谓。
* **数值大**：说明是拐点、尖峰、突变点，必须保留。

这就是为什么它能精准地保留信号中的“特征”而不浪费点数在平直的线段上。

### 举例说明

假设我们有 5 个数据点，代表一个平稳信号中间突然出现一个脉冲，我们要将其降采样为 **3个点**。

**原始数据 (Index: Y值)**：

* **Idx 0**: `10` (起点)
* **Idx 1**: `10` (平稳)
* **Idx 2**: `50` (**突变峰值**)
* **Idx 3**: `10` (平稳)
* **Idx 4**: `10` (终点)

**目标点数**：3

**1. 计算重要性**

* **Idx 0**: 首点 $\rightarrow$ **MAX**
* **Idx 4**: 尾点 $\rightarrow$ **MAX**
* **Idx 1**: |50(Idx2) - 2 × 10(Idx1) + 10(Idx0)| = |50 - 20 + 10| = |40| = **40**
* **Idx 2**: |10(Idx3) - 2 × 50(Idx2) + 10(Idx1)| = |10 - 100 + 10| = |-80| = **80** (弯曲度最大)
* **Idx 3**: |10(Idx4) - 2 × 10(Idx3) + 50(Idx2)| = |10 - 20 + 50| = |40| = **40**

**2. 排序结果**

1. **Idx 0** (MAX)
2. **Idx 4** (MAX)
3. **Idx 2** (Score: 80)
4. Idx 1 (Score: 40)
5. Idx 3 (Score: 40)

**3. 筛选 Top 3**
选中的索引集合为：`{0, 4, 2}`

**4. 重组输出**
按索引排序后：`0 -> 2 -> 4`
**最终结果**：保留了起点、峰值点、终点。
`[10, 50, 10]`

```java
// 1. 初始化首点重要性为无穷大
importances.add(new PointImportance(0, Double.MAX_VALUE));

// 2. 遍历中间点计算二阶差分
        for(
int i = 1; i <data.

size() -1;i++){
double prev = data.get(i - 1).getY().doubleValue();
double curr = data.get(i).getY().doubleValue();
double next = data.get(i + 1).getY().doubleValue();
// 对应公式 |next - 2*curr + prev|
    importances.

add(new PointImportance(i, Math.abs(next-2*curr+prev)));
        }

// 3. 初始化尾点重要性为无穷大
        importances.

add(new PointImportance(data.size() -1,Double.MAX_VALUE));

// 4. 按重要性倒序排序
        importances.

sort((a, b) ->Double.

compare(b.importance, a.importance));

// 5. 取前 targetCount 个点的索引
Set<Integer> selectedIndices = new HashSet<>();
for(
int i = 0; i <Math.

min(targetCount, importances.size());i++){
        selectedIndices.

add(importances.get(i).index);
        }

// 6. 按原始索引顺序重组数据
List<Integer> sortedIndices = new ArrayList<>(selectedIndices);
Collections.

sort(sortedIndices);
```

### 适用场景

这种方法非常适合 **Step（阶跃）** 或 **Pulse（脉冲）** 类型的信号，因为它能极其精准地抓住信号发生突变的关键位置，而不会像普通均匀采样那样可能“漏掉”尖峰。

---

## 二、adaptiveLTTB (自适应LTTB)

`com.yt.server.util.AdaptiveDownsamplingSelector#adaptiveLTTB` 是标准 LTTB (Largest-Triangle-Three-Buckets)
算法的改进版，专门用于处理**非均匀分布**的复杂数据。

它的核心思想是：**按需分配**。即数据变化剧烈（复杂度高）的区域分配更多的采样点，而变化平缓的区域分配较少的点，从而在总点数不变的情况下，最大化保留细节。

### 核心逻辑步骤

1. **数据分段**：将整个数据集切分为多个片段（默认为 10 段），以便进行局部特征分析。
2. **计算复杂度**：对每一段计算其“复杂度”。
    * **计算公式**：该段内所有点垂直变化量（Y轴变化绝对值）的总和 + 1.0（基础分）。
    * **通俗理解**：就是看这段数据在上下跳动了多少次、跳动幅度有多大。跳得越欢，复杂度越高。
3. **动态分配配额**：根据每段复杂度占总复杂度的比例，分配目标点数 (`targetCount`)。
    * **公式**：`SegmentTarget = TotalTarget * (SegmentComplexity / TotalComplexity)`
    * **例如**：如果某一段波动剧烈，占据了总波动量的 50%，那么它将获得 50% 的采样点名额。
4. **局部 LTTB**：对每一段数据，使用分配到的名额执行标准的 LTTB 降采样。
5. **结果合并与去重**：将所有段的采样结果拼接起来。需要特别处理段与段之间的边界点，避免重复添加。

### 举例说明

假设有一段长度为 1000 的数据，目标降采样为 100 点。

**如果是标准 LTTB**：

* 会机械地将前 500 点分成 50 个桶，后 500 点也分成 50 个桶。
* 结果：平缓区域浪费了大量点，而震荡区域因为点数不足而严重失真。

**如果是 adaptiveLTTB**：

1. **分段**：
   我们将数据切分为两段：
    * **第一段（前500点）**：平缓区域，假设平均波动极小（0.1）。
    * **第二段（后500点）**：震荡区域，假设平均波动很大（10.0）。

2. **计算复杂度（关键步骤）**：
   算法会计算每一段的“垂直路径总长度”，作为复杂度的度量。
    * **第一段复杂度** = 500个点 × 平均波动0.1 + 基础分1.0 = **51.0**
    * **第二段复杂度** = 500个点 × 平均波动10.0 + 基础分1.0 = **5001.0**
    * **总复杂度** = 51.0 + 5001.0 = **5052.0**

   *可以看到，虽然两段数据长度一样，但第二段的复杂度是第一段的近100倍。*

3. **分配配额（按需分配）**：
   总共有 **100个** 采样名额，我们按复杂度的比例来瓜分。
    * **第一段能分多少？**
      占比 = 51.0 / 5052.0 ≈ 1%
      名额 = 100 × 1% = **1 个点**
    * **第二段能分多少？**
      占比 = 5001.0 / 5052.0 ≈ 99%
      名额 = 100 × 99% = **99 个点**

4. **执行结果**：
    * 平缓的前半段只用 1 个点概括（因为它本来就没什么变化，1个点足够了）。
    * 剧烈波动的后半段用了 99 个点（保留了极其丰富的细节）。

5. **最终效果**：
   相比标准算法平均分配（各50点），自适应算法将宝贵的采样资源集中到了“刀刃”上，完美还原了后半段的震荡波形，同时没有浪费资源在前半段的直线上。

### 代码对应

```java
// 1. 分段计算复杂度
for(int i = 0;
i<numSegments;i++){
// ... 切分数据 ...
double complexity = calculateSegmentComplexity(segment);
    segmentComplexity.

add(complexity);

totalComplexity +=complexity;
}

// 2. 根据复杂度分配点数并执行 LTTB
        for(
int i = 0;
i<numSegments;i++){
// ...
// 按比例分配点数
int segmentTarget = (int) Math.round(targetCount * segmentComplexity.get(i) / totalComplexity);
segmentTarget =Math.

max(2,segmentTarget); // 至少保留2点

// 执行 LTTB
List<UniPoint> segmentResult = LTThreeBuckets.sorted(segment, segmentTarget);

// ... 合并结果 ...
}
```

### 适用场景

这种方法非常适合**混合型数据**，即数据中同时包含长段的平稳区和局部的剧烈波动区。例如：

* 机器运行日志（长时间待机 + 短时间高负荷工作）
* 金融交易数据（横盘整理 + 剧烈拉升）

---

## 三、calculateNormalizedVolatility (归一化波动率计算)

`com.yt.server.util.AdaptiveDownsamplingSelector#calculateNormalizedVolatility` 用于衡量数据相对于其自身幅度的“抖动”程度，是识别高频噪声与低频信号的关键指标。

**注意**：该方法通常不直接处理原始数据，而是与 `calculateTrendInfo` 方法配合使用，处理去趋势后的**残差序列 (Residuals)**。

### 核心逻辑步骤

1. **前置准备 (calculateTrendInfo)**：首先调用 `calculateTrendInfo` 对原始数据进行线性回归 ($y=ax+b$)，提取出趋势线，并计算出每个点的
   **残差**（Residual = 原始值 - 趋势值）。
2. **输入**：将上一步计算得到的**残差序列**作为输入传递给本方法。
3. **遍历计算**：对于序列中的每一对相邻残差点 $(y_{i-1}, y_i)$：
    * **计算绝对差值**：$|y_i - y_{i-1}|$ （这次跳了多远）
    * **计算平均振幅（基准）**：$(|y_i| + |y_{i-1}|) / 2$ （这大概是在什么水位上跳的）
    * **计算相对变化率**：差值 / 平均振幅
4. **求平均**：将所有点的相对变化率取平均值，得到最终的归一化波动率。

### 为什么需要归一化？

* **绝对波动率**：如果一个信号从 1000 跳到 1001，差值是 1；另一个信号从 1 跳到 2，差值也是 1。绝对波动率认为它们一样。
* **归一化波动率**：
    * 1000 -> 1001：变化率约 0.1% （微小波动，可能是正常趋势）
    * 1 -> 2：变化率 100% （剧烈波动，可能是噪声或突变）
    * 归一化后，能公平地比较不同量级数据的“活跃程度”。

### 举例说明（详细步骤）

为了理解“残差”和“波动率”的关系，我们结合代码中的 `calculateTrendInfo` 和 `calculateNormalizedVolatility` 两个步骤来演示。

#### 场景 1：数据 B（平滑趋势信号）

假设数据是一条完美的上升直线，这就是我们最想保留的“信号”。

* **原始数据**: `[10, 20, 30, 40]`

* **第一步：提取趋势 (对应代码 `calculateTrendInfo`)**
    * 方法内部使用最小二乘法拟合，算出斜率 $slope=10$，截距 $intercept=0$。
    * **趋势模型**: $y = 10x + 0$
    * **预测值 (Fitted)**: `[10, 20, 30, 40]`
    * **计算残差 (Residuals)**:
        * $10 - 10 = 0$
        * $20 - 20 = 0$
        * ...
    * **输出残差序列**: `[0, 0, 0, 0]`

* **第二步：计算波动率 (对应代码 `calculateNormalizedVolatility`)**
    * 输入是上一步产生的 `[0, 0, 0, 0]`。
    * 序列中全是 0，相邻差异为 0。
    * **归一化波动率 = 0.0**

* **结论**：**极低的波动率**意味着原始数据完全符合趋势，**没有噪声**。

---

#### 场景 2：数据 A（高频噪声信号）

假设数据在某个均值上下剧烈反复跳动。

* **原始数据**: `[10, 90, 10, 90]`

* **第一步：提取趋势 (对应代码 `calculateTrendInfo`)**
    * 最小二乘法拟合，因为数据是对称跳动，拟合出的直线是水平的。
    * **趋势模型**: $y = 0x + 50$ (平均值是 50)
    * **预测值 (Fitted)**: `[50, 50, 50, 50]`
    * **计算残差 (Residuals)**:
        * $10 - 50 = -40$
        * $90 - 50 = +40$
        * $10 - 50 = -40$
        * ...
    * **输出残差序列**: `[-40, 40, -40, 40]`

* **第二步：计算波动率 (对应代码 `calculateNormalizedVolatility`)**
    * 输入是 `[-40, 40, -40, 40]`。
    * 计算第一对相邻点 `(-40, 40)`:
        * **变化幅度**: $|40 - (-40)| = 80$
        * **平均振幅**: $(|-40| + |40|) / 2 = 40$
        * **相对变化率**: $80 / 40 = 2.0$ (200%)
    * **归一化波动率 = 2.0**

* **结论**：**极高的波动率**意味着原始数据相对于趋势线在疯狂跳动，判定为**高频噪声**。

### 总结

* **为什么数据 B 残差为 0？** 因为它完美符合线性趋势，没有任何“意外”的抖动。
* **为什么数据 A 波动率高？** 因为它虽然平均值稳定，但每一刻都在剧烈偏离平均值（残差很大且正负交替），导致计算出的相对变化率极高。

### 应用场景

* **噪声识别**：如果归一化波动率很高，说明数据充满了杂乱的随机跳动，适合使用平滑算法或 Min-Max 包络算法。
* **信号分类**：辅助区分“平稳信号”、“趋势信号”和“剧烈震荡信号”，从而选择最合适的降采样策略。

---

## 四、calculateTrendInfo (趋势信息计算/线性回归)

`com.yt.server.util.AdaptiveDownsamplingSelector#calculateTrendInfo` 用于提取数据的**线性趋势**
。它是许多高级特征分析（如波动率计算、周期性检测）的基础。

### 核心逻辑步骤

1. **最小二乘法拟合**：通过计算 $x$ (索引) 和 $y$ (数值) 的协方差与方差，找到一条误差最小的直线 y = slope × x + intercept。
2. **提取参数**：
    * **Slope (斜率)**：表示数据的总体涨跌趋势（正数为涨，负数为跌，0为平）。
    * **Intercept (截距)**：趋势线的起始高度。
3. **计算残差 (Residuals)**：计算每个原始点与趋势线之间的垂直距离。
    * Residual_i = y_i - (slope × i + intercept)
    * 残差反映了去除去趋势后的“纯净”波动/噪声。

### 计算公式 (人类易读版)

**Slope (斜率)** = (N × ∑xy - ∑x × ∑y) / (N × ∑x² - (∑x)²)

**Intercept (截距)** = (∑y - Slope × ∑x) / N

### 举例说明

假设我们有一组略微波动的数据：`[10, 11, 13]`。
索引 ($x$): 0, 1, 2
数值 ($y$): 10, 11, 13
$N = 3$

**1. 基础累加计算**

* ∑x = 0 + 1 + 2 = 3
* ∑y = 10 + 11 + 13 = 34
* ∑xy = (0 × 10) + (1 × 11) + (2 × 13) = 0 + 11 + 26 = 37
* ∑x² = 0² + 1² + 2² = 0 + 1 + 4 = 5

**2. 计算斜率 (Slope)**

* 分子 = 3 × 37 - 3 × 34 = 111 - 102 = 9
* 分母 = 3 × 5 - 3² = 15 - 9 = 6
* Slope = 9 / 6 = 1.5
    * *解读：平均每过一个时间点，数值增长 1.5。*

**3. 计算截距 (Intercept)**

* Intercept = (34 - 1.5 × 3) / 3 = (34 - 4.5) / 3 = 29.5 / 3 ≈ 9.833
* **拟合直线**: $y = 1.5x + 9.833$

**4. 计算残差 (Residuals)**

* **Idx 0**:
    * 实际值: 10
    * 预测值: $1.5 × 0 + 9.833 = 9.833$
    * 残差: $10 - 9.833 = 0.167$
* **Idx 1**:
    * 实际值: 11
    * 预测值: $1.5 × 1 + 9.833 = 11.333$
    * 残差: $11 - 11.333 = -0.333$
* **Idx 2**:
    * 实际值: 13
    * 预测值: $1.5 × 2 + 9.833 = 12.833$
    * 残差: $13 - 12.833 = 0.167$

**最终输出 TrendInfo**:

* Slope: 1.5
* Intercept: 9.833
* Residuals: `[0.167, -0.333, 0.167]` (去除了增长趋势后的纯波动)
* **ResidualRange (极差)**:
    * `Max(Residuals)` = 0.167
    * `Min(Residuals)` = -0.333
    * `Range` = 0.167 - (-0.333) = **0.5**
* **ResidualStdDev (标准差)**:
    * 残差均值 (MeanR) = (0.167 - 0.333 + 0.167) / 3 ≈ 0.0
    * 偏差平方和 = (0.167-0)² + (-0.333-0)² + (0.167-0)²
    * = 0.027889 + 0.110889 + 0.027889 ≈ 0.166667
    * 方差 = 0.166667 / 3 ≈ 0.05555
    * `StdDev` = √0.05555 ≈ **0.2357**

### 适用场景

* **趋势判断**：Slope > 0 为上升趋势，Slope < 0 为下降趋势。
* **去趋势 (Detrending)**：在进行周期性分析（如傅里叶变换或自相关分析）之前，通常需要先减去线性趋势，只保留残差部分，以避免趋势对频率分析的干扰。

### TrendInfo 结果对象详解 (结合代码)

`TrendInfo` 是 `calculateTrendInfo` 方法的返回结果类，用于封装线性回归分析的所有关键指标。

```java
static class TrendInfo {
    double slope;
    double intercept;
    List<Double> residuals = Collections.emptyList();
    double residualRange;
    double residualStdDev;
}
```

#### 字段含义与物理意义

1. **slope (double)**
    * **代码对应**：`info.slope = (n * sumXY - sumX * sumY) / denominator;`
    * **含义**：趋势线的斜率。
    * **物理意义**：表示数据的总体变化速率和方向。
        * `> 0`：总体上升趋势。
        * `< 0`：总体下降趋势。
        * `≈ 0`：总体平稳，无明显趋势。
    * **用途**：判断信号是否发生漂移（Drift），或者计算趋势强度。

2. **intercept (double)**
    * **代码对应**：`info.intercept = (sumY - info.slope * sumX) / n;`
    * **含义**：趋势线的截距（即当 x=0 时趋势线的值）。
    * **物理意义**：趋势线的起始高度。
    * **用途**：确定趋势线在坐标系中的确切位置。

3. **residuals (List<Double>)**
    * **代码对应**：`double residual = data.get(i).getY().doubleValue() - fitted;`
    * **含义**：残差序列列表。
    * **计算公式**：`residuals[i] = 实际值[i] - 趋势预测值[i]`
    * **物理意义**：去除了线性趋势后的“纯净”波动数据。包含了噪声、周期性波动和其他非线性特征。
    * **用途**：这是 `calculateNormalizedVolatility`（归一化波动率）和 `detectPeriodicity`（周期性检测）的核心输入数据。

4. **residualRange (double)**
    * **代码对应**：`info.residualRange = maxR - minR;`
    * **含义**：残差的极差（Range）。
    * **计算公式**：`Max(residuals) - Min(residuals)`
    * **物理意义**：数据围绕趋势线波动的最大幅度。
    * **用途**：衡量波动的绝对范围，用于计算信噪比或包络增长率。

5. **residualStdDev (double)**
    * **代码对应**：`info.residualStdDev = Math.sqrt(Math.max(0, rSumSq / n - meanR * meanR));`
    * **含义**：残差的标准差（Standard Deviation）。
    * **物理意义**：衡量数据围绕趋势线波动的离散程度。
    * **用途**：比 `residualRange` 更稳定地反映波动的平均强度，常用于噪声水平评估。

---

## 五、detectPeriodicity (信号周期性检测)

`com.yt.server.util.AdaptiveDownsamplingSelector#detectPeriodicity` 用于自动识别信号中是否存在重复出现的模式（如正弦波、方波等），并计算其
**周期长度**和**周期强度**。

### 核心逻辑步骤

1. **数据标准化 (Normalize)**：
   周期检测依赖于波形的“形状”相似度，而不应受数值绝对大小的影响。因此，首先将数据转换为**零均值、单位方差**的序列。
    * 也就是让数据以 0 为中心上下波动，且波动幅度归一化。

2. **自相关扫描 (Autocorrelation Scan)**：
   让信号“自己和自己”进行比较。将信号向后平移 `Lag`（滞后）个单位，然后计算平移后的信号与原信号的相关系数。
    * **Lag (滞后)**：平移的时间点数。
   * **Correlation (相关系数)**：衡量两个序列的相似程度。1.0 表示完全正相关（一模一样），-1.0 表示完全负相关（完全相反），0
     表示不相关。

3. **寻找最佳匹配**：
   遍历一定范围内的 Lag 值（从 `n/10` 到 `n/3`），记录下**相关系数最大**的那个 Lag。
    * 如果最大的相关系数 `> 0.3`（阈值），则认为信号具有周期性。
    * 这个 Lag 值就是**周期长度 (Period)**。
    * 相关系数的值就是**周期强度 (Strength)**。

### 核心原理解析：自相关 (Autocorrelation)

想象你有一张波形图的透明胶片。

1. 你拿另一张一模一样的胶片（这就是“自己”）。
2. 两张胶片完全重叠时，透光最强（相关性=1）。
3. 你把上面那张胶片向右平移一点点（Lag增加）。
    * 如果是**随机噪声**，错开一点后，波峰对波谷，乱七八糟，相关性迅速降为 0。
    * 如果是**周期信号**（比如周期为 4），当你平移了 4 个格子时，胶片上的波峰又正好对上了波峰，波谷对上了波谷！此时相关性会突然再次变大（出现峰值）。

### 举例说明

*(请参考下文“综合深度解析”章节中的统一示例，该示例更直观地展示了从残差计算到周期检测的全过程。)*

### Code Mapping (代码对应)

```java
// 核心循环：尝试不同的 Lag
for(int lag = minLag;
lag<maxLag;lag +=step){
// 计算当前 Lag 下的相关系数
double corr = calculateAutocorrelationNormalized(normalized, lag);
// 记录最佳匹配
    if(corr >maxCorr){
maxCorr =corr;
bestLag =lag;
    }
            }

// 阈值判断
            if(maxCorr >0.3){
info.strength =maxCorr; // 周期强度
info.period =bestLag;   // 周期长度
}
```

### 适用场景

* **保留波形特征**：如果检测到强周期性（如正弦波），`AdaptiveDownsamplingSelector` 会优先选择 `HYBRID_ENVELOPE` (混合包络)
  算法，这种算法能很好地保持波形的上下包络，防止降采样导致的“混叠”或波形失真。
* **压缩策略调整**：对于周期信号，知道周期后，可以避免恰好按周期倍数采样（这会导致严重的混叠效应，比如把正弦波采成一条直线）。

---

### 综合深度解析：趋势提取与周期检测的联动机制

为了彻底理解 `calculateTrendInfo` 和 `detectPeriodicity` 是如何协作的，我们将使用**同一个数据集**，贯穿整个计算流程。

**统一示例数据**：
假设我们采集到了 5 个连续的时间点数据：
> `Y值: [10, 22, 14, 26, 18]`

直观上看，这组数据既在**上下震荡**（小波动），又在**整体变大**（大趋势）。如果直接分析周期性，会被上升趋势干扰；如果只看平均值，又会忽略震荡。

下面演示算法是如何一步步拆解它的。

#### 第一步：提取趋势 (calculateTrendInfo)

首先，算法使用**线性回归 (Linear Regression)** 拟合出数据的“大方向”。

**1. 基础统计**

* **X (索引)**: `0, 1, 2, 3, 4`
* **Y (数值)**: `10, 22, 14, 26, 18`
* **计算均值**: AvgX = 2, AvgY = 18

**2. 计算斜率 (Slope)**
通过最小二乘法公式计算：

* **Slope = 2.0**
    * *物理意义：平均每经过一个时间点，数值增加 2.0。*
* **Intercept (截距) = 14.0**
* **拟合直线方程**: $y = 2x + 14$

**3. 计算残差 (Residuals)**
这是最关键的一步。算法计算**实际值**与**趋势预测值**之间的差。

* **Residual = $y_{actual} - (2x + 14)$**

| Index | 实际值 (Y) | 趋势预测 ($2x+14$) | **残差 (Residuals)** |
|:------|:--------|:---------------|:-------------------|
| 0     | 10      | 14             | **-4**             |
| 1     | 22      | 16             | **+6**             |
| 2     | 14      | 18             | **-4**             |
| 3     | 26      | 20             | **+6**             |
| 4     | 18      | 22             | **-4**             |

**阶段产出**：
`TrendInfo` 对象包含了计算出的残差序列：`[-4, 6, -4, 6, -4]`。
这个序列代表了**去除上升趋势后，纯粹的波动信号**。

---

#### 第二步：周期检测 (detectPeriodicity)

现在，`detectPeriodicity` 方法接收上一步生成的**残差序列** `[-4, 6, -4, 6, -4]` 作为输入。

**1. 为什么要用残差？**
如果我们直接用原始数据 `[10, 22...]` 进行平移比较：

* 原始波峰 `22` (Idx 1) 平移后可能去匹配原始波峰 `26` (Idx 3)。
* 虽然它们都是波峰，但数值差了 4 ($26 \neq 22$)，导致匹配度（相关性）下降。

使用残差 `[-4, 6...]`：

* 波峰 `6` 平移后匹配波峰 `6`。
* 数值完全相等！匹配度完美。

**2. 自相关扫描 (Autocorrelation Scan)**

算法将残差序列进行平移（Lag），并与自己对比：

* **尝试 Lag = 1 (平移 1 格)**
    * 原序列: `[-4, 6, -4, 6]` (Idx 0-3)
    * 平移项: `[ 6, -4, 6, -4]` (Idx 1-4)
    * 对比: $(-4 \times 6) + (6 \times -4)...$
    * **结果**: 正负交错，由强烈的**负相关**（波谷对波峰）。

* **尝试 Lag = 2 (平移 2 格) —— 为什么是它？**
    * 原序列: `[-4, 6, -4]` (取前3个点)
    * 平移项: `[-4, 6, -4]` (取后3个点，从 Idx=2 开始)
    * **深度逻辑分析**：
        1. **波形对齐**：
            * 原序列的 **波谷** (-4) 刚好对应平移后的 **波谷** (-4)。
            * 原序列的 **波峰** (6) 刚好对应平移后的 **波峰** (6)。
        2. **数学计算 (点积)**：
            * 相关性的核心是乘积求和。
           * Idx 0 vs Idx 2: (-4) × (-4) = **16** (**负负得正**，贡献极大正值)
           * Idx 1 vs Idx 3: 6 × 6 = **36** (**正正得正**，贡献极大正值)
           * Idx 2 vs Idx 4: (-4) × (-4) = **16** (**负负得正**，贡献极大正值)
    * **结果**：
        * 对于 Lag=1，我们是在算 (-4) × 6 = -24，正负抵消，得分很低。
        * 对于 Lag=2，每一对数据都在**同向共振**，所有乘积都是正数，累加起来得分极高。
        * 这就是**相关系数 = 1.0 (最大值)** 的数学原理。

**3. 最终判定**
算法检测到 **Lag = 2** 时具有极高的相关性。

* **结论**: 信号具有周期性。
* **Period (周期)**: 2
* **Strength (强度)**: High

#### 总结

通过这个统一的例子，我们可以清晰地看到数据是如何流动的：

1. **原始数据** (`10, 22...`) ——[计算趋势]——> **趋势线** (`2x+14`) + **残差** (`-4, 6...`)
2. **残差** (`-4, 6...`) ——[自相关分析]——> **周期信息** (`Period=2`)

这就是为什么源码中会有 `detectPeriodicity(trendInfo.residuals)` 这样的调用链。它是为了让周期检测算法“透过现象（宏观趋势）看本质（微观波动）”。

---

## 六、normalizeSignal (信号标准化)

### 方法签名

`private static List<Double> normalizeSignal(List<Double> values)`

**注意**：尽管该方法的名称是 `normalizeSignal`（标准化信号），但它返回的是一个 `List<Double>`，其中的元素是转换后的 **Z-Score
值（无量纲统计量）**，而不是某种物理单位的信号。

* `List<Double> values`: 输入的原始信号序列。
* `return`: 输出的标准化序列，其中每个值代表原始点偏离均值的标准差倍数。

### 功能说明

该方法用于对输入信号进行**标准化预处理**（Standardization / Z-score Normalization）。即将原始数据转换为**均值为 0、方差为 1
** 的标准正态分布形式。

这是执行高精度统计关联分析（如周期性检测、自相关分析）的关键前置步骤，因为它能消除数据绝对幅值（量纲）的影响，仅保留数据的波动形态特征。

### 核心逻辑步骤

1. **计算统计量**：
    * 计算输入序列的平均值（Mean）。
    * 计算方差（Variance）和标准差（StdDev）。
2. **特殊情况处理**：
    * 如果标准差极小（`stdDev < 1e-6`），说明数据几乎是平坦的直线。此时直接执行去均值操作（x - mean），不进行除法缩放，避免除零错误。
3. **标准化变换**：
    * 对每个数据点应用公式：x_norm = (x - mean) / stdDev。
4. **安全截断（Clipping）**：
    * 为了防止极端异常值破坏后续计算，将标准化后的结果强制限制在 `[-10.0, 10.0]` 范围内。这意味着超过 10 倍标准差的离群点会被截断。

### 举例说明

#### 示例 1：正常波动数据

**输入**: `[10.0, 20.0, 30.0]`

1. **均值**: $(10+20+30)/3 = 20.0$
2. **方差**: $((10-20)^2 + (20-20)^2 + (30-20)^2)/3 = 200/3 \approx 66.67$
3. **标准差**: $\sqrt{66.67} \approx 8.165$
4. **标准化**:
    * $(10 - 20) / 8.165 \approx -1.225$
    * $(20 - 20) / 8.165 = 0.0$
    * $(30 - 20) / 8.165 \approx 1.225$

**结果**: `[-1.225, 0.0, 1.225]`

#### 示例 2：平坦数据（stdDev < 1e-6）

**输入**: `[5.0, 5.0, 5.0]`

1. **均值**: $5.0$
2. **标准差**: $0.0$
3. **处理**: 触发 `stdDev < 1e-6` 分支，仅执行减去均值。

**结果**: `[0.0, 0.0, 0.0]`

#### 示例 3：含极端异常值（触发截断）

**背景说明**：要触发 10 倍标准差的截断，样本量通常需要较大（N > 100）。因为在小样本中，一个巨大的异常值会显著拉高整体的标准差，导致其自身的
Z-score 难以超过 10（数学极限为 $\sqrt{N-1}$）。

**构造输入数据** (共 200 个点)：

* **前 199 个点**: `10.0, 10.0, ..., 10.0` (平稳背景)
* **最后 1 个点**: `2010.0` (突发极端异常值)

**1. 计算统计量**:

* **求和 (Sum)**: `199 * 10.0 + 2010.0 = 1990 + 2010 = 4000.0`
* **均值 (Mean)**: `4000.0 / 200 = 20.0`
* **方差 (Variance)**:
    * 正常点偏差平方和: `199 * (10.0 - 20.0)^2 = 199 * 100 = 19900.0`
    * 异常点偏差平方和: `1 * (2010.0 - 20.0)^2 = 1990^2 = 3960100.0`
    * 总平方和: `3960100.0 + 19900.0 = 3980000.0`
    * 方差: `3980000.0 / 200 = 19900.0`
* **标准差 (StdDev)**: `Math.sqrt(19900.0) ≈ 141.067`

**2. 标准化计算 (针对异常点 2010.0)**:

* **公式**: `raw_norm = (x - Mean) / StdDev`
* **代入**: `(2010.0 - 20.0) / 141.067`
* **结果**: `1990.0 / 141.067 ≈ 14.107`
* **分析**: 该点偏离均值约 14.1 个标准差。

**3. 触发截断**:

* **逻辑**: `Math.max(-10.0, Math.min(10.0, 14.107))`
* **过程**:
    * `Math.min(10.0, 14.107)` -> 返回 `10.0` (上限截断)
    * `Math.max(-10.0, 10.0)` -> 返回 `10.0`
* **最终结果**: 该点的标准化值被限制为 **10.0**。

**4. 最终返回列表 (List<Double>)**:
这个方法返回的是包含所有点标准化结果的列表。对于上述构造的数据：

* **输入**: `[10.0, ..., 10.0, 2010.0]` (200个点)
* **输出**: `[-0.07, ..., -0.07, 10.0]`

  **前 199 个正常点的计算细节**:
    * **原始值**: `10.0`
    * **公式**: `(x - Mean) / StdDev`
    * **代入**: `(10.0 - 20.0) / 141.067`
    * **中间步**: `-10.0 / 141.067`
    * **结果**: `≈ -0.07088` (即列表中的前 199 个值)

  **最后 1 个异常点的计算细节**:
    * **原始值**: `2010.0`
    * **计算**: `(2010.0 - 20.0) / 141.067 ≈ 14.107`
    * **截断**: `Math.min(10.0, 14.107) -> 10.0`

**5. 为什么要这样做？（核心意义）**

如果不进行截断，这个异常值在后续分析中会产生**破坏性影响**：

* **场景**: 后续算法通常涉及“平方”或“乘积”运算（如自相关系数计算）。
* **未截断时**: 异常点值为 `14.1`，其平方权重为 $14.1^2 \approx 200$。这意味着**这 1 个点的影响力等于 200 个正常点**
  。它会像“黑洞”一样吸走所有统计特征，导致算法只关注这个毛刺，而忽略了整体的周期性规律。
* **截断后**: 值为 `10.0`，平方权重为 `100`。它依然被视为“非常重要”的突变，但权重被限制在可控范围内，保证了算法的鲁棒性。

**6. 结果解读**:

* 输出 **10.0** 的物理含义：该数据点是一个**极度异常**的突变点。
* 在标准正态分布中，数值超过 3.0 的概率仅为 0.3%，而超过 10.0 的概率几乎为 0。

---

## 七、calculateAutocorrelationNormalized (标准化自相关计算)

### 方法签名

`private static double calculateAutocorrelationNormalized(List<Double> normalized, int lag)`

* `List<Double> normalized`: 必须是经过 `normalizeSignal` 处理后的 **Z-Score 序列**（无量纲）。
* `int lag`: 滞后量（平移的点数）。
* `return`: 返回在指定 lag 下的相关系数，范围近似 `[-1.0, 1.0]`。

### 功能说明

该方法计算信号与自身在时间平移（Lag）后的相似程度。它是 `detectPeriodicity`（周期检测）的核心算法。

### 与 normalizeSignal 的深度联系

这个方法**必须且只能**接收 `normalizeSignal` 的输出作为输入。

1. **数学原理**：
    * Pearson 相关系数的标准公式：
      `r = sum((x - meanX) * (y - meanY)) / (sqrt(sum((x - meanX)^2)) * sqrt(sum((y - meanY)^2)))`
    * 因为输入已经是 Z-Score（均值 ≈ 0，方差 ≈ 1）：
        * 分子简化为：`sum(x * y)` （直接乘积之和）
        * 分母简化为：`N` （样本数）
    * **结论**：`calculateAutocorrelationNormalized` 极其高效地通过“乘积的平均值”直接估算出了相关系数。

2. **如果输入未标准化数据会怎样？**
    * 计算出的将是**自协方差 (Autocovariance)**，其数值大小取决于信号的绝对幅值（例如可能是 `10000.0` 或 `0.0001`）。
    * 这就无法使用统一的阈值（如代码中的 `0.3`）来判定“是否存在周期性”。

### 举例说明

假设我们有一个简单的周期为 2 的震荡信号。

**1. 原始信号处理**

* **原始数据**: `[10, 20, 10, 20]`
* **normalizeSignal 后**: `[-1.0, 1.0, -1.0, 1.0]` (简化模型，假设标准差恰好归一化到 1)

**2. 计算 Lag = 1 (错位 1 格)**

* **原序列**: `[-1.0, 1.0, -1.0]` (取前 3 个)
* **平移序列**: `[ 1.0, -1.0, 1.0]` (取后 3 个，即向左平移 1 格)
* **逐点相乘**:
    * `(-1.0) * 1.0 = -1.0`
    * `1.0 * (-1.0) = -1.0`
    * `(-1.0) * 1.0 = -1.0`
* **求和**: `-3.0`
* **平均**: `-3.0 / 3 = -1.0`
* **结论**: **-1.0**。代表**完全负相关**。波峰正好对上了波谷，波谷对上了波峰。

**3. 计算 Lag = 2 (错位 2 格)**

* **原序列**: `[-1.0, 1.0]` (取前 2 个)
* **平移序列**: `[-1.0, 1.0]` (取后 2 个，即向左平移 2 格)
* **逐点相乘**:
    * `(-1.0) * (-1.0) = 1.0`
    * `1.0 * 1.0 = 1.0`
* **求和**: `2.0`
* **平均**: `2.0 / 2 = 1.0`
* **结论**: **1.0**。代表**完全正相关**。波峰对上了波峰，说明**周期为 2**。


**4. 计算 Lag = 5 (低相关性/节奏错位示例)**

这是一个更真实的场景：**剧烈波动区**与**平坦区**的错误相遇。

* **场景描述**：
    * **原序列 (High Energy)**：处于信号的剧烈震荡阶段，数值在 `[-2.5, 3.2]` 之间大幅跳动。
    * **平移序列 (Low Energy)**：由于 Lag 移动，对应位置的数据恰好处于信号的静默期或平稳期，数值在 `[-0.2, 0.2]` 之间微小波动。

* **数据演示**:
    * **原序列片段**: `[ 2.5, -1.8,  3.2, -2.1]`  (大起大落)
    * **平移序列片段**: `[ 0.1, -0.2,  0.1,  0.2]`  (微波粼粼)

* **逐点相乘计算**:
    1. ` 2.5 *  0.1 =  0.25`  (原信号大正值，被平移信号的微小值“稀释”)
    2. `-1.8 * -0.2 =  0.36`  (符号偶然相同，贡献一点正值)
    3. ` 3.2 *  0.1 =  0.32`
    4. `-2.1 *  0.2 = -0.42`  (符号相反，贡献负值，抵消了前面的正值)

* **统计结果**:
    * **求和**: `0.25 + 0.36 + 0.32 - 0.42 = 0.51`
    * **平均 (Correlation)**: `0.51 / 4 = 0.1275`

* **结论**: **0.1275 (低相关)**。
    * 虽然原信号在拼命震荡，但平移后的信号**无动于衷**（数值太小），导致乘积积攒不起来。
    * 且乘积中既有正也有负（正负抵消），进一步拉低了总分。
    * 这说明在当前 Lag 下，两个信号**没有共鸣**，判定为无周期性关联。

### 返回值代表的物理意义

该方法返回值的范围理论上为 **[-1.0, 1.0]**，代表了**皮尔逊相关系数 (Pearson Correlation Coefficient)**。

* **1.0 (完全正相关)**
    * **含义**：信号在平移 Lag 个单位后，与原信号**完美重合**。
    * **解读**：找到了极其精准的周期！波峰对波峰，波谷对波谷。
    * **例子**：Lag=2 时返回 1.0，说明每隔 2 个点信号就重复一次（如 `10, 20, 10, 20...`）。

* **-1.0 (完全负相关)**
    * **含义**：信号在平移 Lag 个单位后，与原信号**完全相反**。
    * **解读**：波峰正好对上了波谷。通常意味着 Lag 可能是半个周期。
    * **例子**：Lag=1 时返回 -1.0，说明当前点向上，下一个点必定向下（如 `10, -10, 10, -10...`）。

* **0.0 (无相关性)**
    * **含义**：信号平移后，与原信号毫无关系，杂乱无章。
    * **解读**：数据是随机噪声，或者是 Lag 选择错误，没对上节奏。

* **代码中的阈值 0.3**
    * 在 `detectPeriodicity` 方法中，使用了 `if(maxCorr > 0.3)` 作为判定标准。
    * 这意味着只要相关性**超过 30%**，算法就倾向于认为信号存在一定的周期性规律，从而切换到适合保留波形的降采样策略。

## 八、detectSteps (阶跃检测)

### 方法签名

`private static int detectSteps(List<UniPoint> data)`

### 功能说明

该方法用于识别信号中是否存在**突变（Step/Jump）**。它通过统计学方法（3-Sigma 原则）来判断相邻点之间的变化量是否显著超出了正常波动的范围。

### 核心逻辑步骤

1. **计算一阶差分（First Derivative）**：
    * 遍历数据，计算相邻两点 Y 值的绝对差：`diff = |y_{i+1} - y_i|`。
    * 这个序列反映了信号变化的快慢（即瞬时变化率）。

2. **统计分析**：
    * 计算所有差值的**均值 (Mean)** 和 **标准差 (StdDev)**。

3. **设定阈值 (Threshold)**：
    * 使用 **3-Sigma 准则**：`Threshold = Mean + 3 * StdDev`。
    * 这意味着，如果某个点的跳变幅度超过了平均水平的 3 个标准差，它就被视为一个“异常突变”。

4. **计数**：
    * 统计有多少个差值超过了该阈值（且绝对值 > 0.01，过滤微小抖动）。

### 举例说明

#### 示例 1：平稳信号（无阶跃）

**数据**: `[10, 11, 10, 11, 10]`

1. **差分序列**:
    * |11 - 10| = 1
    * |10 - 11| = 1
    * |11 - 10| = 1
    * |10 - 11| = 1
    * Sequence: `[1, 1, 1, 1]`
2. **统计**:
    * Mean = 1.0
    * StdDev = 0.0
3. **阈值**: `1.0 + 3 * 0.0 = 1.0`
4. **判断**: 没有差值**严格大于** 1.0。
5. **结果**: **0** (无阶跃)

#### 示例 2：含突变信号（阶跃）

**数据**: `[10, 10, 10, 10, 110, 110, 110]`
*(模拟设备从 10 突然跳变到 110)*

1. **差分序列**:
    * 10->10: 0
    * 10->10: 0
    * 10->10: 0
    * 10->110: **100** (突变点)
    * 110->110: 0
    * 110->110: 0
    * Sequence: `[0, 0, 0, 100, 0, 0]` (共6个差值)
2. **统计**:
    * **Sum**: 100
    * **Mean**: 100 / 6 ≈ **16.67**
    * **方差**:
        * 5个0的偏差: $5 \times (0 - 16.67)^2 \approx 1389.4$
        * 1个100的偏差: $1 \times (100 - 16.67)^2 \approx 6943.9$
        * 总和: 8333.3
        * MeanVar: 8333.3 / 6 ≈ 1388.8
    * **StdDev**: $\sqrt{1388.8} \approx 37.26$
3. **阈值**:
    * `Threshold = 16.67 + 3 * 37.26 = 16.67 + 111.78 = 128.45`
    * *注：这里因为样本量太少且异常值极端巨大，导致标准差被拉得非常大，反而可能掩盖异常值（100 <
      128.45）。这是小样本统计的陷阱。*
    * *但在实际大量数据中（例如 100个点），StdDev 会非常小，100 很容易超过阈值。*

   **修正场景（长序列背景）**:
   假设有 99 个 `0` 和 1 个 `100`。
    * Mean ≈ 1
    * StdDev ≈ 10 (大致估算)
    * Threshold ≈ 1 + 30 = 31
    * **100 > 31** -> **检测成功！**

4. **结果**:
   在数据量足够的情况下，突变点会被识别，计数加 1。

### 适用场景

* **开关量检测**：识别设备启停（0 -> 1）。
* **故障诊断**：识别传感器读数突然跳变（如断线、短路导致的数值飞升）。
* **自适应策略**：如果 `detectSteps > 0`，算法会倾向于选择 `SignalType.STEP` 或 `SignalType.PULSE`，进而使用
  `PEAK_DETECTION` (峰值检测) 算法，确保不会把这个关键的跳变给“平均”或“平滑”掉。

**文档结束**

---

## 💡 示例数据计算结果深度汇总

为了便于直观理解，以下是针对序列 `[1, 2, 3, 10, 11]` 的核心识别结论：

1. **宏观形态 (Mean=5.4, Range=10.0, Slope=2.8)**：信号展现出一个非常稳健且剧烈的上升趋势（趋势强度为满分 1.0）。
2. **波动本质 (NormalizedVolatility=1.8, NoiseRatio=0.667)**：虽然信号在 3 到 10 之间有一个很大的跨度，但根据"噪声比"
   分析，其中约
   **66.7%** 的变化来源于非线性抖动，这提示算法在采样时应注意区分趋势与噪声。
3. **统计异类 (StepCount=0)**：尽管 3 到 10 的跳变看起来很大，但在基于 $3\sigma$
   的统计学视角下，它尚未被判定为"突变阶跃"。这解释了为什么特征提取会保持谨慎，而将分类倾向于带有噪声的趋势信号（Trend
   Noise）。
4. **几何保真 (Linearity=0.879)**：约 87.9% 的数据变异可以用一条直线解释，剩下的 12.1% 则是需要降采样算法（如
   LTTB）去重点保护的特征。

**结论**：该参数组合指引降采样器使用 `UNIFORM_WITH_EXTREMES` 或 `ADAPTIVE_LTTB` 算法，以确保在保留 3→10 关键跳变的同时，不被局部噪声带偏。

---

## 九、calculateNoiseRatio (噪声占比计算)

### 方法签名

`private static double calculateNoiseRatio(List<UniPoint> data)`

### 功能说明

该方法用于评估信号中**高频随机噪声**占总变化量的比例。它通过对比**二阶导数(加速度/曲率)**与**一阶导数(速度/总变化)**
的比值来区分"平滑变化"和"随机抖动"。

### 核心逻辑步骤

1. **计算二阶导数(smoothChange)**: 通过三点法计算曲率 `|y[i+1] - 2×y[i] + y[i-1]|`
2. **计算一阶导数(totalChange)**: 计算总位移 `|y[i+1] - y[i-1]|`
3. **求比值**: `noiseRatio = smoothChange / totalChange`

### 核心原理解析：什么是二阶导数(曲率)?

#### 1. 数学定义

在离散数据中,二阶导数通过**三点差分**计算:

> **二阶导数 ≈ (y[i+1] - y[i]) - (y[i] - y[i-1])**  
> **简化为**: `y[i+1] - 2×y[i] + y[i-1]`

**物理意义**:

- **一阶导数** = 变化的快慢(速度)
- **二阶导数** = 变化的变化(加速度/弯曲程度)

#### 2. 直观类比

假设你在开车:

- **一阶导数大** = 车速很快 (例如从0到100km/h)
- **二阶导数大** = 加速/刹车很猛 (例如瞬间从0到100,或突然急刹)

对于数据曲线:

- **一阶导数大** = 数值变化幅度大
- **二阶导数大** = 数值变化**方向**频繁改变(锯齿状/抖动)

---

### 举例说明

#### 示例 1: 平滑线性信号 (低噪声)

**数据**: `[10, 20, 30, 40, 50]` (完美的匀速上升)

**计算过程:**

| i | y[i-1] | y[i] | y[i+1] | 二阶导数                           | 一阶总变化              |
|---|--------|------|--------|--------------------------------|--------------------|
| 1 | 10     | 20   | 30     | \|30-2×20+10\| = \|0\| = **0** | \|30-10\| = **20** |
| 2 | 20     | 30   | 40     | \|40-2×30+20\| = \|0\| = **0** | \|40-20\| = **20** |
| 3 | 30     | 40   | 50     | \|50-2×40+30\| = \|0\| = **0** | \|50-30\| = **20** |

**统计结果:**

```java
smoothChange(二阶导数总和) =0+0+0=0

totalChange(一阶总变化) =20+20+20=60
noiseRatio =0/60=0.0
```

**结论**: **0.0** → 完全无噪声,是纯粹的平滑信号。

---

#### 示例 2: 高频噪声信号

**数据**: `[10, 30, 10, 30, 10]` (剧烈上下震荡)

**直观图:**
```
30 ●     ●     ●
   |     |     |
   |     |     |
10 ● --- ● --- ●
```

**计算过程:**

| i | y[i-1] | y[i] | y[i+1] | 二阶导数                                   | 一阶总变化 (跨两步)       |
|---|--------|------|--------|----------------------------------------|-------------------|
| 1 | 10     | 30   | 10     | \|10-2×30+10\| = \|10-60+10\| = **40** | \|10-10\| = **0** |
| 2 | 30     | 10   | 30     | \|30-2×10+30\| = \|30-20+30\| = **40** | \|30-30\| = **0** |
| 3 | 10     | 30   | 10     | \|10-2×30+10\| = \|10-60+10\| = **40** | \|10-10\| = **0** |

**代码对应:**
```java
for(int i = 1; i <data.

size() -1;i++){
double y0 = data.get(i - 1).getY().doubleValue();  // 10, 30, 10
double y1 = data.get(i).getY().doubleValue();      // 30, 10, 30
double y2 = data.get(i + 1).getY().doubleValue();  // 10, 30, 10

smoothChange +=Math.

abs(y2 -2*y1+y0);  // 40 + 40 + 40

totalChange +=Math.

abs(y2 -y0);            // 0 + 0 + 0
}
```

**统计结果:**
```java
smoothChange(二阶导数总和) =40+40+40=120

totalChange(跨两步的总变化) =0+0+0=0  ←极端情况!

// 实际代码会避免除零,但这个例子很好地展示了:
// 当信号在原地震荡时,虽然总位移为0,但二阶导数(抖动)极大!
```

**重要说明:**  
这个例子中 `totalChange = 0` 是因为每次跨两步都回到了起点。在实际应用中,如果遇到这种情况,代码会返回 `0.0`
避免除零错误。但这恰好完美展示了**二阶导数的威力**: 即使总位移为0,它仍能捕捉到剧烈的震荡!

**结论**: 这是一个**极端噪声**的典型案例 → 信号在原地剧烈抖动,几乎没有实际的位移。

---

#### 示例 3: 真实场景 - 传感器数据

**数据**: `[100, 105, 103, 108, 106, 112, 110]` (趋势上升+小幅抖动)

**直观图:**

```
112      ●
110          ●
108    ●
106        ●
105  ●
103    ●
100●
```

**逐点计算:**

| i | y[i-1] | y[i] | y[i+1] | 二阶导数                               | 一阶总变化           |
|---|--------|------|--------|------------------------------------|-----------------|
| 1 | 100    | 105  | 103    | \|103-2×105+100\| = \|**-7**\| = 7 | \|103-100\| = 3 |
| 2 | 105    | 103  | 108    | \|108-2×103+105\| = \|**7**\| = 7  | \|108-105\| = 3 |
| 3 | 103    | 108  | 106    | \|106-2×108+103\| = \|**-7**\| = 7 | \|106-103\| = 3 |
| 4 | 108    | 106  | 112    | \|112-2×106+108\| = \|**8**\| = 8  | \|112-108\| = 4 |
| 5 | 106    | 112  | 110    | \|110-2×112+106\| = \|**-8**\| = 8 | \|110-106\| = 4 |

**统计结果:**

```java
smoothChange =7+7+7+8+8=37
totalChange =3+3+4+4+3=17
noiseRatio =37/17 ≈ 2.18
```

**结论**: **2.18** → 噪声占比很高,虽然总体在上升,但过程中频繁"拐来拐去"。

---

### 实际代码实现

```java
private static double calculateNoiseRatio(List<UniPoint> data) {
    if (data.size() < 3) return 0.0;

    double totalChange = 0;   // 一阶总变化(速度)
    double smoothChange = 0;  // 二阶总变化(加速度)

    for (int i = 1; i < data.size() - 1; i++) {
        double y0 = data.get(i - 1).getY().doubleValue();
        double y1 = data.get(i).getY().doubleValue();
        double y2 = data.get(i + 1).getY().doubleValue();

        // 🔍 二阶导数: 衡量"拐弯"的剧烈程度
        smoothChange += Math.abs(y2 - 2 * y1 + y0);

        // 🔍 一阶总变化: 从y0到y2的总位移
        totalChange += Math.abs(y2 - y0);
    }

    // 避免除零
    return totalChange < 1e-6 ? 0.0 : smoothChange / totalChange;
}
```

---

### 核心公式详解

#### 为什么用 `|y2 - 2×y1 + y0|` 而不是 `|y2 - y0|`?

**场景对比:**

**平滑上升 (无噪声):**

```
数据: [10, 20, 30]

一阶: |30-10| = 20  (总位移)
二阶: |30-2×20+10| = |30-40+10| = |0| = 0  (加速度为0,匀速)

→ 二阶为0说明完全没有"拐弯",是笔直的线!
```

**锯齿震荡 (高噪声):**

```
数据: [10, 30, 10]

一阶: |10-10| = 0  (起点和终点一样,总位移为0)
二阶: |10-2×30+10| = |10-60+10| = |-40| = 40  (猛烈加速减速)

→ 二阶巨大说明虽然没位移,但过程中猛烈震荡!
```

**这就是为什么二阶导数能精准捕捉"噪声/抖动"的原因!**

---

### 返回值的物理意义

| noiseRatio值   | 信号特征      | 典型场景       |
|---------------|-----------|------------|
| **< 0.2**     | 极低噪声,非常平滑 | 理想正弦波、匀速运动 |
| **0.2 ~ 0.5** | 中等噪声      | 一般传感器数据    |
| **0.5 ~ 1.0** | 高噪声       | 震动信号、电磁干扰  |
| **> 1.0**     | 极高噪声      | 随机白噪声、故障数据 |

**阈值应用 (代码中):**

```java
// AdaptiveDownsamplingSelector.java:489
private static final double NOISE_RATIO_THRESHOLD = 0.5;

// 信号分类逻辑
if(features.volatility >10&&features.noiseRatio >NOISE_RATIO_THRESHOLD){
        return SignalType.NOISE;  // 判定为噪声信号
}
```

---

### 与其他特征的协同使用

#### 场景 1: 区分 "平滑曲线" vs "随机抖动"

```java
// 示例: 两条曲线的总变化量都是100

曲线A:平滑上升 [0→100]
        -totalChange =100
        -smoothChange =0(完全没有拐弯)
        -noiseRatio =0/100=0.0 ✅平滑

曲线B:震荡上升 [0→10→5→15→10→20...]
        -totalChange =100(最终还是从0到100)
        -smoothChange =200(上下拐了很多次)
        -noiseRatio =200/100=2.0 ❌噪声
```

#### 场景 2: 配合 volatility 判断

```java
// 代码中的组合判断:
if(features.volatility >10&&features.noiseRatio >NOISE_RATIO_THRESHOLD){
        return SignalType.NOISE;
}

// 解释:
volatility >10 →

信号变化非常剧烈(总路径长)

noiseRatio >0.5 →

变化方向频繁改变(高频抖动)
→两者结合 =典型的随机噪声!
```

---

### 边界情况处理

#### 情况 1: 数据点过少

```java
if(data.size() < 3)return 0.0;
```

**原因**: 二阶导数需要三个点才能计算,少于3个点无法判断。

#### 情况 2: 总变化量为0

```java
return totalChange< 1e-6?0.0:smoothChange /totalChange;
```

**场景**: 数据完全平坦 `[5, 5, 5, 5]`

- `totalChange = 0` (没有任何位移)
- 返回 `0.0` 而不是除零错误

---

### 实际应用示例

#### 代码中的使用位置

```java
// AdaptiveDownsamplingSelector.java:656
features.noiseRatio =

calculateNoiseRatio(data);

// 在信号分类中的应用:
private static SignalType classifySignal(SignalFeatures features) {
    // ...

    // 1. 识别高噪声信号
    if (features.volatility > 10 && features.noiseRatio > NOISE_RATIO_THRESHOLD) {
        return SignalType.NOISE;
    }

    // 2. 识别带噪声的趋势信号
    if (Math.abs(features.trendSlope) > 0.01 && features.noiseRatio > 0.3) {
        return SignalType.TREND_NOISE;
    }

    // 3. 在 HYBRID_ENVELOPE 算法中的应用
    boolean noisy = features != null && features.noiseRatio > NOISE_RATIO_THRESHOLD;
    filler = noisy
            ? LTThreeBuckets.sorted(data, remaining)      // 噪声数据用LTTB
            : uniformDownsampling(data, remaining);       // 平滑数据用均匀采样

    // ...
}
```

---

### 算法优势

#### 相比简单的"标准差"方法

**标准差问题:**

```
数据A: [0, 100, 0, 100, 0]  (锯齿)
数据B: [0, 20, 40, 60, 80, 100]  (平滑上升)

两者标准差可能相近,但噪声特征完全不同!
```

**二阶导数优势:**

```
数据A: 
  - 二阶导数 = [±200, ±200, ±200...] (剧烈)
  - noiseRatio = 高

数据B: 
  - 二阶导数 = [0, 0, 0...] (平滑)
  - noiseRatio = 低

→ 能精准区分"震荡"和"平滑上升"!
```

---

### 总结

#### 核心公式

```
noiseRatio = Σ|y[i+1] - 2×y[i] + y[i-1]| / Σ|y[i+1] - y[i-1]|
           = 二阶导数累加和 / 一阶总变化
           = 曲率总和 / 总位移
```

#### 物理意义

- **分子**: 衡量"拐弯次数和剧烈程度"
- **分母**: 衡量"总体变化幅度"
- **比值**: 衡量"单位变化中有多少是无效抖动"

#### 应用价值

1. ✅ **信号分类**: 区分 NOISE / TREND_NOISE / COMPLEX
2. ✅ **算法选择**: 噪声信号用特殊算法(UNIFORM_WITH_EXTREMES)
3. ✅ **质量评估**: 判断传感器数据是否受干扰
4. ✅ **预处理决策**: 决定是否需要平滑/滤波

#### 典型阈值

```java
noiseRatio< 0.2  →平滑信号 →可用LTTB保持形状
noiseRatio >0.5  →噪声信号 →用MIN_MAX或极值保护算法
noiseRatio >1.0  →强噪声 →可能需要数据清洗
```

---

## 十、countZeroCrossings (过零率计算)

### 方法签名

`private static int countZeroCrossings(List<UniPoint> data, double baseline)`

### 功能说明

该方法用于计算信号穿过**基准线（Baseline）**的次数。

在信号处理中，"过零率"（Zero-Crossing Rate, ZCR）是一个非常基础且重要的特征，它反映了信号的**频率特性**和**振荡剧烈程度**。
虽然名字叫"过零"，但在本算法中，我们可以指定任意的 `baseline`（通常是信号的均值 Mean），从而计算信号围绕该基准线的震荡频率。

* **高过零率**：意味着信号频繁地在均值上下跳动，通常对应高频信号或高频噪声。
* **低过零率**：意味着信号变化缓慢，长时间停留在均值的一侧，通常对应低频信号或趋势信号。

### 核心逻辑步骤

1. **确定初始状态**：
    * 比较第一个点 `y[0]` 与 `baseline` 的大小关系。
    * 记录 `above = true` (如果 y > baseline) 或 `false`。
2. **遍历计数**：
    * 从第二个点开始遍历整个数据序列。
    * 对于每个点 `y[i]`，判断其是否在 baseline 之上（`currentAbove`）。
    * 如果 `currentAbove` 与前一个状态 `above` **不一致**（即发生了翻转），说明信号穿过了基准线。
    * 计数器 `count` 加 1，并更新当前状态 `above`。
3. **返回结果**：返回总的穿过次数。

### 核心原理图解

假设 `baseline = 0`：

```text
      +10 |      /^\      (above=true)
          |     /   ----------|----/-----\---------- baseline (0)
          |   /       \   /
      -10 |  /         \_/    (above=false)
```

* 当线条从上往下穿过横轴时，计 1 次。
* 当线条从下往上穿过横轴时，计 1 次。

### 举例说明

#### 示例 1：高频振荡信号

**数据**: `[10, -10, 10, -10, 10]`
**基准线 (Baseline)**: `0.0`

* **i=0**: `10 > 0` -> `above = true`
* **i=1**: `-10 < 0` -> `current = false` (≠ above) -> **Count = 1**, `above = false`
* **i=2**: `10 > 0`  -> `current = true`  (≠ above) -> **Count = 2**, `above = true`
* **i=3**: `-10 < 0` -> `current = false` (≠ above) -> **Count = 3**, `above = false`
* **i=4**: `10 > 0`  -> `current = true`  (≠ above) -> **Count = 4**, `above = true`

**结果**: **4**。
**解读**: 信号在 5 个点内穿过基准线 4 次，说明这是频率极高的震荡信号。

#### 示例 2：低频趋势信号

**数据**: `[-5, -2, 1, 3, 5]` (缓慢上升)
**基准线 (Baseline)**: `0.0`

* **i=0**: `-5 < 0` -> `above = false`
* **i=1**: `-2 < 0` -> `current = false` (== above) -> Count不变
* **i=2**: `1 > 0`  -> `current = true`  (≠ above) -> **Count = 1**, `above = true`
* **i=3**: `3 > 0`  -> `current = true`  (== above) -> Count不变
* **i=4**: `5 > 0`  -> `current = true`  (== above) -> Count不变

**结果**: **1**。
**解读**: 信号只穿过了一次基准线，说明这是一个单调变化的趋势信号，频率很低。

### 代码实现细节

```java
private static int countZeroCrossings(List<UniPoint> data, double baseline) {
    if (data.size() < 2) return 0;

    int count = 0;
    // 1. 初始化状态
    boolean above = data.get(0).getY().doubleValue() > baseline;

    for (int i = 1; i < data.size(); i++) {
        // 2. 判断当前状态
        boolean currentAbove = data.get(i).getY().doubleValue() > baseline;

        // 3. 状态翻转检测
        if (currentAbove != above) {
            count++;
            above = currentAbove; // 更新状态
        }
    }
    return count;
}
```

### 适用场景与应用

在 中，虽然 的结果包含在 中，但在当前的 逻辑中，它主要作为一个辅助特征。

但在更复杂的信号分析中，它的作用包括：

1. **基频估算**：对于周期信号，`频率 ≈ 过零率 / 2`。这可以用来辅助校验 `detectPeriodicity` 计算出的周期是否准确。
2. **静音检测**：在音频处理中，低过零率通常对应静音或浊音，高过零率对应清音（噪音）。
3. **模式识别**：区分 "缓慢漂移"（ZeroCrossings ≈ 0）和 "围绕均值波动"（ZeroCrossings >> 0）。

### 局限性

* **对噪声敏感**：如果信号在基准线附近有微小的随机抖动（例如 0.01, -0.01, 0.01），会导致过零率虚高。
    * *解决方案*：通常需要引入一个 "死区" (Dead Zone) 或滞回比较器 (Hysteresis)，只有跳变幅度超过一定阈值才计数。但当前实现是一个简单的几何过零检测。

---

## 十一、hybridEnvelopeDownsampling (混合包络降采样)

### 方法签名

`private static List<UniPoint> hybridEnvelopeDownsampling(List<UniPoint> data, int targetCount, SignalFeatures features)`

### 功能说明

这是**v4.0版本**专为**周期性信号和调幅信号**设计的核心算法。它通过三层混合采样策略,确保在极高压缩比下仍能保留信号的*
*完整波形包络**,防止出现视觉失真(混叠/莫尔纹)。

### 设计背景

**问题**: 传统LTTB算法在处理高频周期信号时,容易产生**混叠现象**:

```
原始正弦波 (1000点):
∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿

LTTB降采样到100点后:
∿ · · · ∿ · · ∿ · · · ∿
↑ 部分周期的峰谷丢失,波形不连续

HYBRID_ENVELOPE降采样到100点:
∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿∿
↑ 上下包络完整,视觉上呈现"实心"效果
```

**解决方案**: 将采样配额分成三层:

1. **包络层 (40%)**: 保留每个桶的Min/Max,勾勒上下边界
2. **中心带层 (30%)**: 保留接近均值的点,防止中间掏空
3. **填充层 (30%)**: 用LTTB或均匀采样补充细节

---

### 核心逻辑步骤

#### 第一步: 配额分配

```java
int envelopeQuota = (int) (targetCount * 0.40);  // 40% → 包络点
int centerQuota = (int) (targetCount * 0.30);    // 30% → 中心带点
int fillerQuota = targetCount - envelopeQuota - centerQuota;  // 30% → 填充点
```

**设计原理**:

- **40%包络**: 从v4.0的35%提升,确保高压缩比下每个周期都有峰谷代表
- **30%中心带**: 保留信号的"骨干"趋势,对调幅信号尤为重要
- **30%填充**: 补充几何细节,避免过度稀疏

#### 第二步: 包络采样 (MinMaxDownsampler)

调用 `MinMaxDownsampler.downsample(data, envelopeQuota)`,在每个桶中同时保留:

- **最大值点** (波峰)
- **最小值点** (波谷)

**示例 (12点→6点的包络采样):**

```
原始数据: [5, 8, 9, 6, 2, 1, 4, 7, 3, 5, 8, 6]

分2个桶 (每桶6点):
桶1: [5, 8, 9, 6, 2, 1]
  → Min=1, Max=9
  → 按时间顺序: [9(Idx2), 1(Idx5)]

桶2: [4, 7, 3, 5, 8, 6]
  → Min=3, Max=8
  → 按时间顺序: [3(Idx8), 8(Idx10)]

包络结果: [9, 1, 3, 8]  (4个点,勾勒出上下包络)
```

#### 第三步: 中心带采样 (sampleCentralBand)

在每个桶内寻找**最接近均值**的点:

**核心代码:**
```java
private static List<UniPoint> sampleCentralBand(List<UniPoint> data, int quota) {
    int bucketCount = Math.min(Math.max(1, quota * 2), data.size());
    double bucketWidth = (double) data.size() / bucketCount;

    List<UniPoint> selected = new ArrayList<>(quota);
    for (int i = 0; i < bucketCount && selected.size() < quota; i++) {
        int start = (int) Math.floor(i * bucketWidth);
        int end = (int) Math.min(data.size(), Math.round((i + 1) * bucketWidth));

        // 计算该桶的均值
        double sum = 0;
        for (int j = start; j < end; j++)
            sum += data.get(j).getY().doubleValue();
        double baseline = sum / (end - start);

        // 找最接近均值的点
        UniPoint closest = null;
        double bestDiff = Double.MAX_VALUE;
        for (int j = start; j < end; j++) {
            double diff = Math.abs(data.get(j).getY().doubleValue() - baseline);
            if (diff < bestDiff) {
                bestDiff = diff;
                closest = data.get(j);
            }
        }
        if (closest != null) selected.add(closest);
    }
    return selected;
}
```

**示例 (同样的12点数据,目标2个中心点):**

```
桶1: [5, 8, 9, 6, 2, 1]
  均值 = (5+8+9+6+2+1)/6 ≈ 5.17
  最接近点 = 5 (Idx0, diff=0.17)

桶2: [4, 7, 3, 5, 8, 6]
  均值 = (4+7+3+5+8+6)/6 ≈ 5.5
  最接近点 = 5 (Idx9, diff=0.5)

中心带结果: [5(Idx0), 5(Idx9)]
```

#### 第四步: 填充采样

根据信号的噪声特性选择填充策略:

```java
boolean noisy = features != null && features.noiseRatio > NOISE_RATIO_THRESHOLD;
filler =noisy
    ?LTThreeBuckets.

sorted(data, fillerQuota)      // 噪声数据用LTTB
    :

uniformDownsampling(data, fillerQuota);       // 平滑数据用均匀采样
```

**示例 (假设是平滑信号,需要2个填充点):**

```
uniformDownsampling([原始12点], 2):
  → 均匀步长采样
  → 结果: [点3, 点9] (均匀分布在时间轴)
```

#### 第五步: 合并去重
LinkedHashSet<UniPoint> merged = new LinkedHashSet<>(targetCount);
merged.addAll(envelope); // 4个包络点
merged.addAll(centralBand); // 2个中心点
merged.addAll(filler); // 2个填充点

// 去除边界重复点
if (!result.isEmpty() && !windowResult.isEmpty()) {
if (pointsEqual(result.get(result.size() - 1), windowResult.get(0))) {
windowResult = windowResult.subList(1, windowResult.size());
}
}

// 按时间排序
mergedList.sort(Comparator.comparing(UniPoint::getX));
```

---

### 完整实例演示

#### 场景: 调幅正弦波

**原始数据 (20点):**

```
振幅线性增长的正弦波:
t=0~4:   [5, 8, 5, 2, 5]      (振幅±3)
t=5~9:   [5, 10, 5, 0, 5]     (振幅±5)
t=10~14: [5, 12, 5, -2, 5]    (振幅±7)
t=15~19: [5, 14, 5, -4, 5]    (振幅±9)
```

**直观图:**

```
14      ●
12    ●
10  ●
8 ●
5 ●●●●●●●●●●●●●●●●  (中心线)
2   ●
0     ●
-2      ●
-4        ●
```

**目标**: 降采样到 **10个点**

#### 步骤1: 配额分配

```java
envelopeQuota =(int)(10*0.40)=4
centerQuota   =(int)(10*0.30)=3
fillerQuota   =10-4-3=3
```

#### 步骤2: 包络采样 (4个点)

**MinMaxDownsampler处理:**

```
分2个桶 (每桶10点):

桶1 [t=0~9]:
  Min = 0 (t=8)
  Max = 10 (t=6)
  → 按时间: [10(t=6), 0(t=8)]

桶2 [t=10~19]:
  Min = -4 (t=18)
  Max = 14 (t=16)
  → 按时间: [14(t=16), -4(t=18)]

包络结果: [10, 0, 14, -4]
```

#### 步骤3: 中心带采样 (3个点)

**分3个桶,每桶找最接近均值的点:**

```
桶1 [t=0~6]:
  均值 ≈ 5.4
  最接近 = 5 (t=0或t=4,选t=0)

桶2 [t=7~13]:
  均值 ≈ 4.3
  最接近 = 5 (t=10)

桶3 [t=14~19]:
  均值 ≈ 4.7
  最接近 = 5 (t=15或t=19,选t=15)

中心带结果: [5(t=0), 5(t=10), 5(t=15)]
```

#### 步骤4: 填充采样 (3个点)

**假设是平滑信号,用均匀采样:**

```
uniformDownsampling(20点, 3):
  步长 = 19 / (3-1) = 9.5
  → 选择: t=0, t=10, t=19

填充结果: [5(t=0), 5(t=10), 5(t=19)]
```

#### 步骤5: 合并去重

```java
merged ={
        // 包络
        10(t=6),0(t=8),14(t=16),-4(t=18),
        // 中心带
        5(t=0),5(t=10),5(t=15),
        // 填充
        5(t=0)[重复,去除],5(t=10)[重复,去除],5(t=19)
        }

// 去重后
merged ={5(t=0),10(t=6),0(t=8),5(t=10),5(t=15),14(t=16),-4(t=18),5(t=19)}

// 排序后
result =[5,10,0,5,5,14,-4,5](8个点)
```

#### 步骤6: 归一化 (确保10个点)

```java
// 当前8个点 < 目标10个点
// 调用 normalizeToTargetV4 补充2个点
// 最终输出10个点 (具体补点逻辑见fillGaps方法)
```

---

### 视觉效果对比

#### 原始数据 (20点):

```
14      ●
12    ●  
10  ●    
8 ●      
5 ●●●●●●●●●●●●●●●●
2   ●    
0     ●  
-2      ●
-4        ●
```

#### LTTB降采样 (10点) - ❌ 包络不完整:

```
14      ●
12       
10      
8 ●      
5 ●  ●    ●  ●  ●
2        
0     ●  
-2       
-4        ●
```

**问题**: 中间的峰值(t=11, y=12)丢失,包络不连续!

#### HYBRID_ENVELOPE降采样 (10点) - ✅ 包络完整:

```
14      ●
12       
10  ●    
8        
5 ●    ●  ●  ●  ●
2        
0     ●  
-2       
-4        ●
```

**优势**: 所有周期的峰谷都被保留,上下包络连续完整!

---

### 关键设计细节

#### 1. 为什么包络占40% (v4.0提升)

**v3.0配置**: 35%包络 + 35%中心 + 30%填充
**v4.0配置**: 40%包络 + 30%中心 + 30%填充

**提升原因**:

```
假设100点压缩到10点,有10个周期:

v3.0: 35%×10 = 3.5点 → 每个周期约0.35点 (不足1个峰谷对)
v4.0: 40%×10 = 4点   → 每个周期约0.4点  (更接近1个峰谷对)

→ 5%的提升确保了高压缩比下的包络完整性!
```

#### 2. 中心带采样的重要性

**对比场景: 调幅信号**

**只有包络,无中心带:**

```
14      ●
10  ●    
5                    ← 中心线消失!
0     ●  
-4        ●
```

看不出中心线在y=5,难以判断是否在零点震荡。

**有中心带:**

```
14      ●
10  ●    
5 ●    ●  ●  ●  ●  ← 中心线清晰可见!
0     ●  
-4        ●
```

清晰展示了信号围绕y=5震荡,且振幅逐渐增大。

#### 3. 填充策略的自适应

```java
boolean noisy = features.noiseRatio > NOISE_RATIO_THRESHOLD;

// 高噪声信号 (noiseRatio > 0.5)
filler =LTThreeBuckets.

sorted(data, fillerQuota);
// → LTTB能更好地保留噪声信号的"随机性"特征

// 平滑信号 (noiseRatio ≤ 0.5)
filler =

uniformDownsampling(data, fillerQuota);
// → 均匀采样确保时间轴分布的规律性
```

---

### 适用场景

#### ✅ 强烈推荐使用

1. **周期性信号 (PERIODIC)**
    - 标准正弦波/方波
    - 转速监控数据
    - 交流电压/电流波形

2. **调幅信号 (AMPLITUDE_MODULATED)**
    - 电机启动过程 (振幅逐渐增大)
    - 震荡发散/收敛信号
    - 载波调制信号

3. **高压缩比场景 (Compression > 10)**
    - 1000点 → 100点
    - 10000点 → 500点
    - 需要保留完整波形包络

#### ❌ 不推荐使用

1. **线性信号 (LINEAR)**
    - 用LTTB更合适,几何保真度更高

2. **阶跃信号 (STEP/PULSE)**
    - 用PEAK_DETECTION更精准

3. **纯噪声信号 (NOISE)**
    - v5.0应使用UNIFORM_WITH_EXTREMES

---

### 性能特点

#### 时间复杂度

```
MinMaxDownsampler:  O(n)  - 单次遍历找min/max
sampleCentralBand:  O(n)  - 单次遍历找最接近均值点
Filler (LTTB):      O(n)  - LTTB算法
合并去重:            O(k log k) - k为targetCount

总复杂度: O(n + k log k) ≈ O(n)
```

#### 空间复杂度

```
临时集合:
- envelope: O(k)
- centralBand: O(k)
- filler: O(k)
- merged: O(k)

总复杂度: O(k) - k为targetCount
```

---

### 实际代码片段

```java
private static List<UniPoint> hybridEnvelopeDownsampling(
        List<UniPoint> data, int targetCount, SignalFeatures features) {

    if (CollectionUtils.isEmpty(data) || targetCount <= 0)
        return data;

    int safeTarget = Math.min(Math.max(targetCount, 2), data.size());
    if (safeTarget <= 5)
        return MinMaxDownsampler.downsample(data, safeTarget);

    // 🔥 v4.0 配额分配
    int envelopeQuota = Math.max(4, (int) Math.round(safeTarget * 0.4));
    int centerQuota = Math.max(2, (int) Math.round(safeTarget * 0.3));
    int fillerQuota = Math.max(0, safeTarget - envelopeQuota - centerQuota);

    // 第一层: 包络采样
    List<UniPoint> envelope = MinMaxDownsampler.downsample(data, envelopeQuota);

    // 第二层: 中心带采样
    List<UniPoint> centralBand = sampleCentralBand(data, centerQuota);

    // 第三层: 填充采样
    List<UniPoint> filler = Collections.emptyList();
    int remaining = safeTarget - envelope.size() - centralBand.size();
    if (remaining > 0) {
        boolean noisy = features != null && features.noiseRatio > NOISE_RATIO_THRESHOLD;
        filler = noisy ? LTThreeBuckets.sorted(data, remaining)
                : uniformDownsampling(data, remaining);
    }

    // 合并去重
    LinkedHashSet<UniPoint> merged = new LinkedHashSet<>(safeTarget);
    merged.addAll(envelope);
    merged.addAll(centralBand);
    for (UniPoint point : filler) {
        if (merged.size() >= safeTarget) break;
        merged.add(point);
    }

    // 补齐不足的点
    if (merged.size() < safeTarget) {
        for (UniPoint point : data) {
            if (merged.add(point) && merged.size() >= safeTarget)
                break;
        }
    }

    List<UniPoint> result = new ArrayList<>(merged);
    result.sort(Comparator.comparing(UniPoint::getX));

    // 裁剪多余的点
    return result.size() > safeTarget
            ? balancedUniformTrim(result, safeTarget)
            : result;
}
```

---

### 总结

#### 核心优势

1. ✅ **包络完整**: 40%配额专门保留峰谷,确保波形上下边界清晰
2. ✅ **中心趋势**: 30%配额保留"骨干",防止中间掏空
3. ✅ **自适应填充**: 根据噪声特性选择LTTB或均匀采样
4. ✅ **视觉保真**: 在极高压缩比下仍能呈现"实心"波形效果

#### 典型应用

```java
// 在算法路由矩阵中的位置
if(signalType ==SignalType.PERIODIC ||
signalType ==SignalType.AMPLITUDE_MODULATED){
        return DownsamplingAlgorithm.HYBRID_ENVELOPE;
}
```

#### 与其他算法对比

| 维度        | LTTB  | MIN_MAX | HYBRID_ENVELOPE |
|-----------|-------|---------|-----------------|
| **几何保真**  | ⭐⭐⭐⭐⭐ | ⭐⭐⭐     | ⭐⭐⭐⭐            |
| **包络保护**  | ⭐⭐⭐   | ⭐⭐⭐⭐⭐   | ⭐⭐⭐⭐⭐           |
| **中心带保留** | ❌     | ❌       | ⭐⭐⭐⭐⭐           |
| **周期性信号** | ⭐⭐⭐   | ⭐⭐⭐⭐    | ⭐⭐⭐⭐⭐           |
| **调幅信号**  | ⭐⭐    | ⭐⭐⭐     | ⭐⭐⭐⭐⭐           |
| **高压缩比**  | ⭐⭐    | ⭐⭐⭐⭐    | ⭐⭐⭐⭐⭐           |

**结论**: HYBRID_ENVELOPE 是处理周期性和调幅信号的**终极方案**,特别是在压缩比>10的极端场景下,能完美保持波形的视觉完整性!
