## 时序数据降采样算法优化总结

本项目针对大规模时序数据的可视化展示，实现并迭代了一套动态降采样算法，旨在保证数据视觉保真度的同时，大幅提升前端渲染性能。核心优化点如下：

### 1. 动态算法选择策略
- **问题**: 单一的 LTTB (Largest-Triangle-Three-Buckets) 算法在处理高频、周期性信号（如正弦波）时，会产生视觉混叠（aliasing），导致图形严重失真。
- **解决方案**: 引入 **"波动指数" (Volatility Index)** 概念，该指标通过计算`总垂直距离 / 垂直范围`来量化数据的波动特性。
    - **波动指数 > 阈值**: 判断为高频、周期性数据，选用 **Min-Max 算法**，保留每个采样区间的最大值和最小值，确保数据波动范围的保真度。
    - **波动指数 <= 阈值**: 判断为趋势性数据，继续使用 **LTTB 算法**，它能更好地保留数据的整体趋势和视觉特征。
- **核心实现**: `com.yt.server.util.DownsamplingAlgorithmSelector.java`

### 2. 混合/窗口化处理机制
- **问题**: 对于一个包含多种信号特征（例如，一段平稳趋势后跟一段剧烈波动）的长时序数据，单一的波动指数无法准确评估其全局特性。
- **解决方案**: 实现了一套混合处理（Hybrid/Windowed）机制。该机制将整个数据集切分为固定大小的窗口（例如，512个点），然后独立计算每个窗口的波动指数，并为该
  窗口选择最合适的降采样算法。
- **优势**: 这种更精细化的处理方式，使得降采样策略能动态适应数据局部特征的变化，极大地提升了对复杂信号的视觉保真度。
- **核心实现**: `DownsamplingAlgorithmSelector.java` 中的 `downsample` 方法。

### 3. 算法行为一致性
- **问题**: 标准 LTTB 算法保证保留原始数据的第一个和最后一个点，而自定义的 Min-Max
  算法在早期实现中未提供此保证，导致两种算法切换时，图表可能出现边界点丢失的问题。
- **解决方案**: 重构了 `MinMaxDownsampler.java`，确保其在处理逻辑中显式保留数据集的第一个和最后一个点。
- **优势**: 统一了两种算法在边界处理上的行为，确保了数据在任何情况下都具有一致的起止点，避免了视觉上的断裂或跳跃。

### 4. 全链路应用
- **问题**: 最初，动态降采样选择逻辑仅在实时数据接入时（`HandleWasteTimeService`）被调用。在进行历史数据查询和二次降采样时（`IoComposeServiceDatabase`），
  仍然硬编码使用 LTTB 算法。
- **解决方案**: 在 `IoComposeServiceDatabase` 中，将所有硬编码的 `LTThreeBuckets.sorted()` 调用替换为对 `DownsamplingAlgorithmSelector.downsample()`
  的调用。
- **优势**: 确保了无论是实时数据还是历史数据查询，都能享受到动态算法选择带来的性能和保真度提升，保证了系统行为的全局一致性。
